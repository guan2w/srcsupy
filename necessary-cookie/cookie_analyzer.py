#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Cookieå¿…è¦æ€§åˆ†æå·¥å…·
ç”¨äºç¡®å®šcurlè¯·æ±‚ä¸­å“ªäº›cookieé¡¹æ˜¯å¿…é¡»çš„
"""

import requests
import json
import re
import sys
import time
import argparse
import os
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from urllib.parse import unquote

class CookieAnalyzer:
    def __init__(self, expected_key: str = "status", delay: float = 0.5, retry_count: int = 3):
        """
        åˆå§‹åŒ–Cookieåˆ†æå™¨
        
        Args:
            expected_key: æœŸæœ›åœ¨å“åº”JSONä¸­å­˜åœ¨çš„é”®
            delay: è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰
            retry_count: ç½‘ç»œå¼‚å¸¸é‡è¯•æ¬¡æ•°
        """
        self.expected_key = expected_key
        self.delay = delay
        self.retry_count = retry_count
        self.session = requests.Session()
        
    def parse_curl_command(self, curl_command: str) -> Tuple[str, Dict[str, str], Dict[str, str]]:
        """
        è§£æcurlå‘½ä»¤ï¼Œæå–URLã€headerså’Œcookies
        
        Args:
            curl_command: curlå‘½ä»¤å­—ç¬¦ä¸²
            
        Returns:
            (url, headers, cookies)
        """
        # æå–URL
        url_match = re.search(r"curl\s+'([^']+)'", curl_command)
        if not url_match:
            raise ValueError("æ— æ³•ä»curlå‘½ä»¤ä¸­æå–URL")
        url = url_match.group(1)
        
        # æå–headers
        headers = {}
        header_pattern = r"-H\s+'([^:]+):\s*([^']+)'"
        for match in re.finditer(header_pattern, curl_command):
            key, value = match.groups()
            headers[key] = value
            
        # æå–cookies
        cookies = {}
        cookie_match = re.search(r"-b\s+'([^']+)'", curl_command)
        if cookie_match:
            cookie_string = cookie_match.group(1)
            cookie_pairs = cookie_string.split('; ')
            for pair in cookie_pairs:
                if '=' in pair:
                    key, value = pair.split('=', 1)
                    cookies[key.strip()] = value.strip()
        
        return url, headers, cookies
    
    def _is_network_error(self, exception: Exception) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºç½‘ç»œç›¸å…³å¼‚å¸¸
        
        Args:
            exception: å¼‚å¸¸å¯¹è±¡
            
        Returns:
            æ˜¯å¦ä¸ºç½‘ç»œå¼‚å¸¸
        """
        error_message = str(exception).lower()
        network_errors = [
            'read timed out',
            'timeout',
            'connection error',
            'connection timeout',
            'connection refused',
            'network is unreachable',
            'name resolution failed',
            'connection aborted',
            'connection reset'
        ]
        return any(error in error_message for error in network_errors)
    
    def test_request(self, url: str, headers: Dict[str, str], cookies: Dict[str, str], return_data: bool = False) -> Tuple[bool, Optional[Dict]]:
        """
        æµ‹è¯•è¯·æ±‚æ˜¯å¦æˆåŠŸï¼Œæ”¯æŒç½‘ç»œå¼‚å¸¸é‡è¯•
        
        Args:
            url: è¯·æ±‚URL
            headers: è¯·æ±‚å¤´
            cookies: cookieå­—å…¸
            return_data: æ˜¯å¦è¿”å›å“åº”æ•°æ®
            
        Returns:
            å¦‚æœreturn_dataä¸ºTrueï¼Œè¿”å›(æ˜¯å¦æˆåŠŸ, å“åº”æ•°æ®)
            å¦‚æœreturn_dataä¸ºFalseï¼Œè¿”å›(æ˜¯å¦æˆåŠŸ, None)
        """
        last_exception = None
        
        for attempt in range(self.retry_count + 1):  # åŒ…æ‹¬ç¬¬ä¸€æ¬¡å°è¯•
            try:
                response = self.session.get(url, headers=headers, cookies=cookies, timeout=30)
                
                # æ£€æŸ¥çŠ¶æ€ç 
                if response.status_code != 200:
                    return False, None
                    
                # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦ä¸ºJSONä¸”åŒ…å«æœŸæœ›çš„é”®
                try:
                    json_data = response.json()
                    success = self.expected_key in json_data
                    if return_data and success:
                        return success, json_data
                    else:
                        return success, None
                except (json.JSONDecodeError, KeyError):
                    return False, None
                    
            except Exception as e:
                last_exception = e
                
                # å¦‚æœæ˜¯ç½‘ç»œå¼‚å¸¸ä¸”è¿˜æœ‰é‡è¯•æœºä¼š
                if self._is_network_error(e) and attempt < self.retry_count:
                    print(f"    âš ï¸  ç½‘ç»œå¼‚å¸¸ (ç¬¬{attempt + 1}æ¬¡å°è¯•): {e}")
                    print(f"    ğŸ”„ {self.delay}ç§’åé‡è¯•...")
                    time.sleep(self.delay)
                    continue
                else:
                    # éç½‘ç»œå¼‚å¸¸æˆ–å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°
                    if self._is_network_error(e):
                        print(f"    âŒ ç½‘ç»œå¼‚å¸¸ (å·²é‡è¯•{self.retry_count}æ¬¡): {e}")
                    else:
                        print(f"    âŒ è¯·æ±‚å¼‚å¸¸: {e}")
                    return False, None
        
        return False, None
    
    def find_necessary_cookies(self, url: str, headers: Dict[str, str], cookies: Dict[str, str]) -> Dict[str, str]:
        """
        é€šè¿‡é€é¡¹ç§»é™¤çš„æ–¹å¼æ‰¾åˆ°å¿…è¦çš„cookie
        
        Args:
            url: è¯·æ±‚URL
            headers: è¯·æ±‚å¤´
            cookies: å®Œæ•´çš„cookieå­—å…¸
            
        Returns:
            å¿…è¦çš„cookieå­—å…¸
        """
        print(f"å¼€å§‹åˆ†æï¼Œå…±æœ‰ {len(cookies)} ä¸ªcookieé¡¹...")
        print(f"æœŸæœ›å“åº”åŒ…å«é”®: {self.expected_key}")
        print("-" * 50)
        
        # é¦–å…ˆæµ‹è¯•å®Œæ•´çš„cookieæ˜¯å¦å·¥ä½œ
        print("æµ‹è¯•å®Œæ•´cookie...")
        if not self.test_request(url, headers, cookies)[0]:
            print("âŒ å®Œæ•´cookieè¯·æ±‚å¤±è´¥ï¼è¯·æ£€æŸ¥curlå‘½ä»¤æ˜¯å¦æ­£ç¡®")
            return {}
        print("âœ… å®Œæ•´cookieè¯·æ±‚æˆåŠŸ")
        
        necessary_cookies = cookies.copy()
        removed_cookies = []
        
        # é€ä¸ªå°è¯•ç§»é™¤cookie
        for cookie_name in list(cookies.keys()):
            print(f"\nå°è¯•ç§»é™¤cookie: {cookie_name}")
            
            # åˆ›å»ºä¸´æ—¶cookieå­—å…¸ï¼ˆç§»é™¤å½“å‰cookieï¼‰
            temp_cookies = necessary_cookies.copy()
            if cookie_name in temp_cookies:
                removed_value = temp_cookies.pop(cookie_name)
                
                # æµ‹è¯•ç§»é™¤åæ˜¯å¦ä»ç„¶æˆåŠŸ
                time.sleep(self.delay)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                success, data = self.test_request(url, headers, temp_cookies, True)
                if success:
                    print(f"  âœ… å¯ä»¥ç§»é™¤ '{cookie_name}'")
                    necessary_cookies = temp_cookies
                    removed_cookies.append((cookie_name, removed_value))
                    # æ‰“å°æŒ‡å®šé”®çš„å€¼çš„å‰100ä¸ªå­—ç¬¦
                    if data and self.expected_key in data:
                        key_value = str(data[self.expected_key])
                        print(f"    ğŸ“„ {self.expected_key}: {key_value[:100]}{'...' if len(key_value) > 100 else ''}")
                else:
                    print(f"  âŒ ä¸èƒ½ç§»é™¤ '{cookie_name}' - è¿™æ˜¯å¿…è¦çš„cookie")
        
        print(f"\n" + "="*60)
        print(f"åˆ†æå®Œæˆï¼")
        print(f"åŸå§‹cookieæ•°é‡: {len(cookies)}")
        print(f"å¿…è¦cookieæ•°é‡: {len(necessary_cookies)}")
        print(f"å·²ç§»é™¤cookieæ•°é‡: {len(removed_cookies)}")
        
        if removed_cookies:
            print(f"\nå·²ç§»é™¤çš„cookie:")
            for name, value in removed_cookies:
                print(f"  - {name}: {value[:50]}...")
        
        if necessary_cookies:
            print(f"\nâœ… å¿…è¦çš„cookie:")
            for name, value in necessary_cookies.items():
                print(f"  - {name}: {value[:50]}...")
        
        return necessary_cookies
    
    def generate_minimal_curl(self, url: str, headers: Dict[str, str], necessary_cookies: Dict[str, str]) -> str:
        """
        ç”Ÿæˆä½¿ç”¨æœ€å°å¿…è¦cookieçš„curlå‘½ä»¤
        
        Args:
            url: è¯·æ±‚URL
            headers: è¯·æ±‚å¤´
            necessary_cookies: å¿…è¦çš„cookieå­—å…¸
            
        Returns:
            æœ€å°åŒ–çš„curlå‘½ä»¤
        """
        curl_parts = [f"curl '{url}'"]
        
        # æ·»åŠ headers
        for key, value in headers.items():
            curl_parts.append(f"  -H '{key}: {value}'")
        
        # æ·»åŠ å¿…è¦çš„cookies
        if necessary_cookies:
            cookie_string = '; '.join([f"{k}={v}" for k, v in necessary_cookies.items()])
            curl_parts.append(f"  -b '{cookie_string}'")
        
        return " \\\n".join(curl_parts)

def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Cookieå¿…è¦æ€§åˆ†æå·¥å…· - ç¡®å®šcurlè¯·æ±‚ä¸­å“ªäº›cookieæ˜¯å¿…é¡»çš„",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python cookie_analyzer.py                           # ä½¿ç”¨é»˜è®¤é…ç½®
  python cookie_analyzer.py --delay 2.0               # è®¾ç½®è¯·æ±‚é—´éš”ä¸º2ç§’
  python cookie_analyzer.py --retry 5                 # è®¾ç½®é‡è¯•æ¬¡æ•°ä¸º5æ¬¡
  python cookie_analyzer.py --file my_curls.txt       # ä½¿ç”¨è‡ªå®šä¹‰curlæ–‡ä»¶
  python cookie_analyzer.py --output-dir ./my_results # è‡ªå®šä¹‰è¾“å‡ºç›®å½•
        """
    )
    
    parser.add_argument(
        "--delay", "-d",
        type=float,
        default=1.0,
        help="è¯·æ±‚é—´éš”æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1.0ç§’"
    )
    
    parser.add_argument(
        "--retry", "-r", 
        type=int,
        default=3,
        help="ç½‘ç»œå¼‚å¸¸é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤3æ¬¡"
    )
    
    parser.add_argument(
        "--file", "-f",
        type=str,
        default="curl.txt",
        help="curlå‘½ä»¤æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤curl.txt"
    )
    
    parser.add_argument(
        "--output-dir", "-o",
        type=str,
        default="result",
        help="ç»“æœè¾“å‡ºç›®å½•ï¼Œé»˜è®¤result"
    )
    
    parser.add_argument(
        "--quiet", "-q",
        action="store_true",
        help="é™é»˜æ¨¡å¼ï¼Œå‡å°‘è¾“å‡ºä¿¡æ¯"
    )
    
    return parser.parse_args()

def ensure_output_dir(output_dir: str) -> str:
    """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨å¹¶è¿”å›æ—¶é—´æˆ³å‰ç¼€"""
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”Ÿæˆæ—¶é—´æˆ³å‰ç¼€ YYMMDD.hhmmss-
    timestamp = datetime.now().strftime("%y%m%d.%H%M%S-")
    return timestamp

def main():
    """ä¸»å‡½æ•°ï¼Œä»curl.txtæ–‡ä»¶è¯»å–å‘½ä»¤å¹¶è¿›è¡Œåˆ†æ"""
    args = parse_arguments()
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨å¹¶è·å–æ—¶é—´æˆ³å‰ç¼€
    timestamp_prefix = ensure_output_dir(args.output_dir)
    
    if not args.quiet:
        print("=" * 60)
        print("Cookieå¿…è¦æ€§åˆ†æå·¥å…·")
        print("=" * 60)
        print(f"é…ç½®: å»¶è¿Ÿ={args.delay}s, é‡è¯•={args.retry}æ¬¡, æ–‡ä»¶={args.file}")
        print(f"è¾“å‡º: {args.output_dir}/ (å‰ç¼€: {timestamp_prefix})")
        print("-" * 60)
    
    try:
        # åŠ¨æ€å¯¼å…¥ä»¥æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶è·¯å¾„
        sys.path.insert(0, os.path.dirname(os.path.abspath(args.file)))
        from curl_reader import CurlFileReader
        
        # è¯»å–curlå‘½ä»¤
        reader = CurlFileReader(args.file)
        commands = reader.read_all_commands()
        
        if not commands:
            print(f"âŒ {args.file}æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„curlå‘½ä»¤")
            print(f"ğŸ’¡ è¯·åœ¨{args.file}æ–‡ä»¶ä¸­æ·»åŠ curlå‘½ä»¤ï¼Œæ ¼å¼å‚è€ƒæ–‡ä»¶æ³¨é‡Š")
            return
        
        if not args.quiet:
            print(f"ä»{args.file}è¯»å–åˆ° {len(commands)} ä¸ªcurlå‘½ä»¤:")
            for i, cmd in enumerate(commands, 1):
                print(f"  {i}. {cmd.name} (æœŸæœ›é”®: {cmd.expected_key})")
                sys.stdout.flush()  # å¼ºåˆ¶åˆ·æ–°è¾“å‡ºç¼“å†²åŒº
            print()  # æ·»åŠ ç©ºè¡Œç¡®ä¿è¾“å‡ºå®Œæ•´
        
        # é€‰æ‹©è¦åˆ†æçš„å‘½ä»¤
        if len(commands) == 1:
            selected_cmd = commands[0]
            if not args.quiet:
                print(f"\nè‡ªåŠ¨é€‰æ‹©: {selected_cmd.name}")
        else:
            while True:
                try:
                    choice = input(f"\nè¯·é€‰æ‹©è¦åˆ†æçš„å‘½ä»¤ (1-{len(commands)}): ").strip()
                    choice_idx = int(choice) - 1
                    if 0 <= choice_idx < len(commands):
                        selected_cmd = commands[choice_idx]
                        break
                    else:
                        print(f"è¯·è¾“å…¥1-{len(commands)}ä¹‹é—´çš„æ•°å­—")
                except ValueError:
                    print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        
        # åˆ›å»ºåˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ
        if not args.quiet:
            print(f"\nå¼€å§‹åˆ†æ: {selected_cmd.name}")
            print("-" * 40)
        
        analyzer = CookieAnalyzer(
            expected_key=selected_cmd.expected_key, 
            delay=args.delay, 
            retry_count=args.retry
        )
        
        # è§£æcurlå‘½ä»¤
        url, headers, cookies = analyzer.parse_curl_command(selected_cmd.curl_command)
        
        if not args.quiet:
            print(f"ğŸ“ URL: {url[:60]}{'...' if len(url) > 60 else ''}")
            print(f"ğŸ“„ Headers: {len(headers)} ä¸ª")
            print(f"ğŸª Cookies: {len(cookies)} ä¸ª")
        
        if len(cookies) == 0:
            print("âš ï¸  è¯¥å‘½ä»¤æ²¡æœ‰cookieï¼Œæ— éœ€åˆ†æ")
            return
        
        # åˆ†æå¿…è¦çš„cookie
        necessary_cookies = analyzer.find_necessary_cookies(url, headers, cookies)
        
        # ç”Ÿæˆç»“æœæ–‡ä»¶
        if necessary_cookies or len(cookies) > 0:
            if not args.quiet:
                print(f"\n" + "="*60)
                print("ç”Ÿæˆæœ€å°åŒ–curlå‘½ä»¤:")
                print("-" * 60)
            
            minimal_curl = analyzer.generate_minimal_curl(url, headers, necessary_cookies)
            if not args.quiet:
                print(minimal_curl)
            
            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆä½¿ç”¨æ—¶é—´æˆ³å‰ç¼€ï¼‰
            safe_name = selected_cmd.name.replace(' ', '_').replace('/', '_').replace('\\', '_')
            output_prefix = os.path.join(args.output_dir, f"{timestamp_prefix}{safe_name}")
            
            # ä¿å­˜æœ€å°åŒ–curlå‘½ä»¤
            curl_file = f"{output_prefix}_minimal_curl.sh"
            with open(curl_file, "w", encoding="utf-8") as f:
                f.write("#!/bin/bash\n")
                f.write(f"# æœ€å°åŒ–çš„curlå‘½ä»¤: {selected_cmd.name}\n")
                f.write(f"# åˆ†ææ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"# é…ç½®: å»¶è¿Ÿ={args.delay}s, é‡è¯•={args.retry}æ¬¡\n\n")
                f.write(minimal_curl)
            
            # ä¿å­˜åˆ†æç»“æœ
            result_file = f"{output_prefix}_analysis_result.json"
            with open(result_file, "w", encoding="utf-8") as f:
                result = {
                    "command_name": selected_cmd.name,
                    "analysis_time": time.strftime('%Y-%m-%d %H:%M:%S'),
                    "timestamp_prefix": timestamp_prefix,
                    "config": {
                        "delay": args.delay,
                        "retry_count": args.retry,
                        "expected_key": selected_cmd.expected_key
                    },
                    "original_cookies_count": len(cookies),
                    "necessary_cookies_count": len(necessary_cookies),
                    "necessary_cookies": necessary_cookies,
                    "removed_cookies_count": len(cookies) - len(necessary_cookies),
                    "url": url
                }
                json.dump(result, f, indent=2, ensure_ascii=False)
            
            print(f"\nâœ… ç»“æœå·²ä¿å­˜:")
            print(f"  ğŸ“ {curl_file}")
            print(f"  ğŸ“Š {result_file}")
        else:
            print(f"\nâœ¨ æ‰€æœ‰cookieéƒ½å¯ä»¥ç§»é™¤ï¼Œè¯¥è¯·æ±‚ä¸ä¾èµ–ä»»ä½•cookieï¼")
        
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶é”™è¯¯: {e}")
        print(f"ğŸ’¡ è¯·ç¡®ä¿{args.file}æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®")
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        if not args.quiet:
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()